RESUMEN PROPUESTA FINAL: Centralización de Datos y Analítica – Elanco Animal Health (Operación CASA)
Fecha: 10 de noviembre de 2025 | Versión: 2.04 (Con ABAP Developer) | Norma: < 1000 palabras
================================================================================

CONTEXTO Y PROBLEMA
Elanco opera en más de 10 países de Centro y Sudamérica. Finanzas y Supply Chain dependen hoy de procesos manuales: descargar reportes de múltiples transacciones SAP por país, consolidar en Excel y reconstruir indicadores cada periodo. Esto genera alto consumo de tiempo semanal, datos fragmentados y decisiones lentas basadas en información desactualizada. Power BI Pro existe pero está subutilizado porque los dashboards se conectan a archivos locales sin un repositorio único. Un piloto previo con BigQuery se detuvo por permisos SAP incompletos y tablas faltantes.

OBJETIVO DE LA PROPUESTA
Aunergia implementará una solución integral que automatiza la extracción desde SAP hacia Google BigQuery y construye dashboards ejecutivos en Power BI. Se busca reducir en 70% el tiempo de consolidación y disponer de dashboards en <24h tras el cierre mensual (vs 5–7 días actuales), habilitando analítica confiable para toda la región CASA.

ALCANCE
18 transacciones SAP prioritarias (FI, SD, MM, CO) cubriendo mayor general, órdenes de venta, inventarios, compras, cuentas por pagar, cuentas por cobrar y OPEX. Data Lake en BigQuery con 3 zonas: RAW (crudo), PROCESSED (limpio/transformado) y CURATED (modelo dimensional). 12 dashboards ejecutivos: Financiero General, Ventas, Inventario, OPEX, Supply Chain, Compras, Rentabilidad, CxP, CxC, Controlling, Dashboard Ejecutivo consolidado y uno transversal de desempeño. Seguridad RLS por país y área; actualizaciones automatizadas.

PIPELINE TECNOLÓGICO
Fuente: SAP S/4HANA (FI, CO, SD, MM). Replicación: SAP Landscape Transformation (SLT). Repositorio: BigQuery (dataset `casa_bi` en dev / qa / prod). Herramientas: BigQuery Studio para SQL y validaciones. Visualización: Power BI Service (8 licencias Pro ya disponibles). Modelo dimensional con dimensiones Tiempo, Geografía, Producto, Cliente, Proveedor, Centro y Cuenta Contable.

FASES DEL PROYECTO (36 semanas)
Fase 0 – Revisión de Alcance y Factibilidad (6 semanas, 328h): Auditoría técnica, validación de disponibilidad de tablas SAP en BigQuery, priorización de transacciones, plan refinado y una Prueba de Concepto (POC) end-to-end. Cierra con reunión Go/No-Go.
Fase 1 – Construcción Data Lake (20 semanas, 852h): Pipelines automatizados para las 18 transacciones, ingestión histórica (≥24 meses), 3 zonas de datos, controles de calidad y validaciones SAP vs BigQuery (>95% exactitud objetivo).
Fase 2 – Modelado y Dashboards (10 semanas, 700h): Diseño de modelo dimensional, desarrollo de 12 dashboards, RLS, UAT, capacitación y Go-Live.
Fase 3 – Modelos Predictivos (Conceptual, fuera de alcance de implementación): Documento con catálogo de casos de uso (p.ej. forecast ventas, optimización inventario, morosidad, fraude) y roadmap futuro.

ESFUERZO Y RECURSOS (Total: 1.880h)
Fase 0: 328h | Fase 1: 852h | Fase 2: 700h. Equipo: Consultor BI (935h), ABAP Developer (270h), Funcional SAP (512h), Project Manager (163h). Inicio propuesto: 6-ene-2026 | Fin estimado: 13-sep-2026.

ENTREGABLES PRINCIPALES
Fase 0: Reporte auditoría técnica, backlog priorizado, arquitectura detallada, plan y cronograma refinado, decisión Go/No-Go. 
Fase 1: Data Lake operativo (3 zonas), pipelines funcionando con monitoreo, documentación técnica (diccionarios, diagramas), reporte validación SAP–BigQuery. 
Fase 2: 12 dashboards publicados con RLS, documentación funcional, manuales y capacitación, reportes UAT firmados, Go-Live formal. 
Fase 3 (conceptual): Documento de casos de uso y roadmap ML.

BENEFICIOS ESPERADOS
Reducción del 70% en tiempo de extracción y consolidación. Dashboards disponibles en <24h tras cierre mensual. Eliminación de procesos manuales propensos a error. Acceso democratizado a datos con versión única de la verdad y trazabilidad. Base sólida para futura analítica avanzada (ML).

REQUISITOS Y DEPENDENCIAS
Permisos SAP completos y tablas necesarias replicadas en BigQuery (tickets pendientes a resolver por TI Global). Asignación de accesos BigQuery (rol Data Editor) al equipo. Disponibilidad de stakeholders para validaciones (~4h/semana). Activación y asignación correcta de licencias Power BI Pro. Definición formal de Product Owner.

RIESGOS Y MITIGACIÓN
Tablas o transacciones custom faltantes: mitigación con auditoría exhaustiva en Fase 0 y opción de Change Request ABAP especializado. Retrasos de TI Global: holguras en cronograma y seguimiento semanal. Cambios de alcance: proceso formal de Change Request. Performance BigQuery: diseño con particionamiento/clustering y pruebas anticipadas.

EXCLUSIONES
No incluye costos de infraestructura GCP, compra de licencias (Power BI ya adquiridas), herramientas ETL de terceros (Fivetran, Airbyte), transacciones SAP adicionales, dashboards extra, integraciones externas (CRM, HRIS) ni implementación de modelos predictivos (Fase 3 solo conceptual).

CRITERIOS DE ÉXITO
Replicación satisfactoria de 32–38 tablas asociadas a las 18 transacciones. Exactitud ≥95% entre SAP y BigQuery. Dashboards productivos con RLS aplicado. Usuarios clave capacitados y conformidad formal basada en evidencias técnicas objetivas.

PRÓXIMOS PASOS
Tras aceptación: firma de contrato (3–5 días hábiles), acuerdo comercial sobre 1.880h, programación del kick-off (6-ene-2026), gestión de accesos SAP/BigQuery/Power BI y arranque de Fase 0. Validez de esta propuesta: 30 días desde la fecha (vence 10-dic-2025).

================================================================================
Aunergia – Consultoría en Optimización de Procesos y TI | Resumen Ejecutivo
================================================================================


