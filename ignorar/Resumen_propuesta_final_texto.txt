Propuesta de Centralización de Datos de Análisis
(Propuesta)

Tabla de Contenidos
Propuesta de Centralización de Datos de Análisis	1
Introducción	2
Contexto y problema	2
Objetivo de la propuesta	2
Alcance del proyecto	2
Pipeline tecnológico	3
Descripción general de la propuesta	4
Fases del proyecto	4
Fase 0: Revisión del alcance y factibilidad	4
Fase 1: Construcción del Data Lake	4
Fase 2: Modelado y Dashboards	4
Fase 3: Propuesta de modelos predictivos	5
Esfuerzo, recursos y cronograma	5
Entregables principales	5
Beneficios esperados	5
Requisitos y dependencias	6
Exclusiones y criterios de éxito	6
Próximos pasos	6


Introducción
Contexto y problema
Elanco Animal Health, operando en más de 10 países de Centroamérica y Sudamérica, enfrenta desafíos significativos en la gestión de datos. Los equipos de Finanzas y Supply Chain dependen de procesos manuales e intensivos para extraer y consolidar información desde SAP. Esto implica que los usuarios descarguen reportes individuales de múltiples transacciones SAP por cada país y los consoliden manualmente en hojas de cálculo Excel, consumiendo un tiempo considerable cada semana. Esta fragmentación de la información impide realizar análisis integrados y conduce a una toma de decisiones lenta basada en datos desactualizados. Aunque la compañía cuenta con licencias Power BI Pro, estas están subutilizadas porque los dashboards se conectan a archivos Excel locales sin una fuente de datos centralizada y confiable. Un intento piloto previo con BigQuery no tuvo éxito debido a permisos SAP insuficientes y tablas faltantes en el Data Lake.
Objetivo de la propuesta
Aunergia propone implementar una solución integral que automatice la extracción de datos desde SAP hacia Google BigQuery y desarrolle dashboards ejecutivos en Power BI. El proyecto eliminará los procesos manuales, centralizará la información de todos los países de la región CASA y habilitará capacidades analíticas avanzadas. El objetivo principal es reducir el tiempo dedicado a la consolidación de datos y permitir que los dashboards estén disponibles en 1 a 2 días del cierre mensual, en contraste con los plazos actuales (5 a 7 días).
Alcance del proyecto
El alcance abarca 18 transacciones SAP prioritarias distribuidas en los módulos de Finanzas (FI), Ventas (SD), Materiales (MM) y Controlling (CO). Estas transacciones cubren operaciones críticas como mayor general, órdenes de venta, inventarios, compras, cuentas por pagar, cuentas por cobrar y OPEX. Se implementará un Data Lake en BigQuery con una arquitectura de tres zonas: RAW para datos crudos, PROCESSED para datos limpios y transformados, y CURATED para el modelo dimensional listo para el consumo. Como resultado, se desarrollarán 12 dashboards ejecutivos en Power BI que cubrirán áreas clave como Financiero General, Ventas, Inventario, OPEX, Supply Chain, Compras, Rentabilidad, Cuentas por Pagar, Cuentas por Cobrar, Controlling y un Dashboard Ejecutivo consolidado. Todos los dashboards se actualizarán de manera automatizada.
En cuanto a tablas, el rango de replicación vigente para el MVP extendido es de 32–38 tablas (32 núcleo + hasta 6 condicionales). La estrategia minimiza la replicación usando Universal Journal (ACDOCA/ACDOCA_T) en lugar de BSEG/COEP/FAGLFLEXA, promoviendo tablas semánticas clave y activando condicionales (VBEP, KONV, CE1XXXX/CE4XXXX, MCHB, VBFA, STXL) sólo si existe una justificación.
Pipeline tecnológico
La solución se basa en un stack tecnológico robusto y moderno. La fuente de datos principal es el ERP SAP S/4HANA. Para la replicación de datos se utilizará el servidor SAP Landscape Transformation (SLT). El repositorio centralizado será un Data Lake en Google BigQuery, utilizando el dataset casa_bi en ambientes de desarrollo, calidad y producción. Para la visualización, se empleará Microsoft Power BI, aprovechando las licencias Pro ya adquiridas por Elanco. El proyecto se apoyará en BigQuery Studio para el desarrollo de consultas.


Descripción general de la propuesta
Fases del proyecto
El proyecto se ejecutará en 42 semanas, divididas en las siguientes fases:
    • Fase 0: Revisión del alcance y factibilidad
    • Fase 1: Construcción del Data Lake
    • Fase 2: Modelado y Dashboards
    • Fase 3: Propuesta de modelos predictivos
Fase 0: Revisión del alcance y factibilidad
La Fase 0, de Revisión de Alcance y Factibilidad (6 semanas), incluye una auditoría técnica completa, validación de la disponibilidad de tablas SAP en BigQuery, priorización de transacciones con los stakeholders y un Prueba de Concepto (POC) técnico de extremo a extremo. Culmina con una reunión crítica de Go/No-Go para decidir la continuidad del proyecto.
Resumen de tareas: Fase 0 abarca diseño de arquitectura preliminar, estimación de esfuerzos ETL, kick-off, inventario técnico y revisión de permisos, gestión de tickets críticos, workshops y análisis Z, diseño y PoC, documentación y decisión Go/No-Go.
Fase 1: Construcción del Data Lake
La Fase 1, de Construcción del Data Lake (22 semanas), se centra en implementar pipelines automatizados para extraer y transformar datos de las 18 transacciones SAP hacia BigQuery. Se configurarán las tres zonas de datos, se implementará la historificación de al menos 24 meses y se realizarán validaciones cruzadas para asegurar la precisión de los datos.
Resumen de tareas: Fase 1 incluye setup de infraestructura (datasets, particionamiento, cuentas de servicio, conectividad SLT), desarrollo secuencial de pipelines por módulo (FI, SD, MM Procurement, MM Inventory, ZLEL008, CO/AP/AR, Master Data y ZVEL015) y un bloque de optimización y automatización.
Fase 2: Modelado y Dashboards
La Fase 2, de Modelado y Dashboards (14 semanas), consiste en el diseño del modelo dimensional, el desarrollo de los 12 dashboards en Power BI, las pruebas de aceptación de usuario (UAT) y la capacitación a los usuarios finales antes del Go-Live.
Resumen de tareas: Fase 2 cubre el modelo dimensional (star schema y KPIs), desarrollo de los 12 dashboards (Financieros, Ventas y Rentabilidad, Supply Chain, Tesorería y Ejecutivo), testing integrado y UAT por áreas, además de ajustes finales, documentación, capacitación y Go-Live.
Fase 3: Propuesta de modelos predictivos
La Fase 3 corresponde a una etapa conceptual enfocada en la identificación y evaluación de casos de uso potenciales para modelos predictivos, utilizando las capacidades analíticas y de machine learning disponibles en el ecosistema de la solución, como BigQuery ML, complementadas con visualizaciones avanzadas en Power BI. Durante esta fase se analizarán patrones y correlaciones en los datos integrados para definir hipótesis predictivas de valor para el negocio (por ejemplo, estimaciones de demanda, comportamiento de ventas o eficiencia operativa). Esta etapa no contempla el desarrollo ni la implementación de los modelos, sino que culminará con la entrega de una propuesta técnica detallada que incluirá los casos priorizados, su justificación de negocio, las fuentes de datos requeridas, los enfoques algorítmicos recomendados y las consideraciones para su ejecución en una fase posterior del proyecto.
Esfuerzo, recursos y cronograma
El esfuerzo total del proyecto es de 1.590 horas distribuidas a lo largo de 42 semanas. La Fase 0 requiere 235 horas, la Fase 1 necesita 696 horas y la Fase 2 demanda 659 horas. El equipo de Aunergia estará compuesto por un Arquitecto de Datos y Desarrollador principal (961 horas), un Analista SAP y Power User (484 horas) y un Project Manager (145 horas). La fecha de inicio propuesta es el 6 de enero de 2026, con una finalización estimada a mediados de octubre de 2026.
Entregables principales
Los entregables clave por fase son: 
    • En la Fase 0, un reporte de auditoría técnica, un backlog priorizado, la arquitectura detallada del Data Lake, un plan de proyecto actualizado y la decisión formal de Go/No-Go. 
    • En la Fase 1, el Data Lake operativo en BigQuery con las tres zonas, los pipelines automatizados funcionando, documentación técnica completa y un reporte de validación de datos. 
    • En la Fase 2, los 12 dashboards publicados en Power BI Service, manuales de capacitación, reportes de pruebas de aceptación firmados y el Go-Live formal. 
    • En la Fase 3, se entregará el documento con la propuesta de los modelos predictivos.
Beneficios esperados
Se anticipan ahorros operativos significativos, con una reducción del tiempo de extracción y consolidación de datos, liberando una cantidad sustancial de horas al año para las áreas de Finanzas y Supply Chain. La disponibilidad de la información se acelerará drásticamente, con dashboards listos en 1 a 2 días tras el cierre mensual. Se eliminarán los procesos manuales propensos a errores y se democratizará el acceso a los datos a través de Power BI, estableciendo una versión única de la verdad para todo el área.
Requisitos y dependencias
Para el éxito del proyecto es crítico contar con los permisos SAP necesarios y asegurar la disponibilidad de las tablas requeridas en BigQuery. Se requiere la disponibilidad de los stakeholders para validaciones y responder a los tickets críticos en un plazo máximo de una semana. Los riesgos identificados incluyen la falta de disponibilidad de tablas SAP y posibles retrasos en la respuesta del soporte de TI. Las estrategias de mitigación incluyen un análisis exhaustivo en la Fase 0, la consideración de modificaciones mediante Change Request y la incorporación de holguras en el cronograma. Los cambios de alcance se manejarán a través de un proceso formal de Change Request.
Exclusiones y criterios de éxito
No están incluidos en el alcance los costos de infraestructura de Google Cloud Platform, transacciones SAP adicionales más allá de las 18 planificadas, dashboards extras, integraciones con otros sistemas o la implementación de modelos predictivos. El proyecto se considerará exitoso si las tablas SAP identificadas (entre 32 y 38) están replicadas en BigQuery, la exactitud de los datos entre SAP y BigQuery es igual o superior al 95%, los usuarios han sido capacitados adecuadamente y existe una conformidad formal basada en criterios técnicos objetivos y verificables; además, si se aplica la estrategia de minimización de replicación (ACDOCA/ACDOCA_T sustituyen BSEG/COEP/FAGLFLEXA y las tablas condicionales se activan sólo cuando estén justificadas).
Próximos pasos
Los próximos pasos, una vez aceptada la propuesta, son la firma del contrato formal, la definición del acuerdo comercial, la programación de la reunión de kick-off para el 6 de enero de 2026 y el inicio de los trámites para los accesos necesarios a los sistemas. La validez de esta propuesta es de 30 días a partir de su emisión. Este proyecto representa una transformación digital crucial para Elanco, modernizando sus procesos analíticos, eliminando tareas manuales repetitivas y permitiendo una toma de decisiones ágil y basada en información confiable y actualizada.
